#separator:tab
#html:true
#guid column:1
#notetype column:2
#deck column:3
#tags column:6
j;-G)+o}cp	Basic	SnykAdjacent::ML	what is Deep Learning?	Deep Learning is a subset of ML based on artificial neural networks	
LcZUZ:fAy*	Basic	SnykAdjacent::ML	what are foundation models?	<strong>Foundation models</strong> are large-scale artificial intelligence models&nbsp;	
em))42&ol	Basic	SnykAdjacent::ML	are foundation models specific or versatile?	These models are highly versatile&nbsp;	
"OJOw26#>QM"	Basic	SnykAdjacent::ML	generative AI : powered by an engine, foundation model : ?	the core engine	
r,aM2phXBv	Basic	SnykAdjacent::ML	LLMS are a subset of what?	Foundation Models	
nhd/q/ft}N	Basic	SnykAdjacent::ML	LLM stands for what?	Large Language Model	
k>-79}$;{h	Basic	SnykAdjacent::ML	what are LLMS designed to understand?	specifically designed to understand and generate text	
dm24Az$[]&	Basic	SnykAdjacent::ML	what is&nbsp;<strong>Tokenization?</strong>	The process of converting text into smaller units (tokens), such as words or subwords	
jb!G7VY;C_	Basic	SnykAdjacent::ML	what kind of tasks can foundation models be used for?	foundation models&nbsp;can be adapted to a wide range of tasks and applications	
IW|TTM3nAa	Basic	SnykAdjacent::ML	how large are foundation model data sets?	foundation models&nbsp;have been trained on vast amounts of data	
bW7?b$L_4M	Basic	SnykAdjacent::ML	how do deep learning algorithms learn?	algorithms learn from large amounts of data to identify patterns and make decisions	
uOwws:PAK}	Basic	SnykAdjacent::ML	what does GAN stand for?	<strong>Generative Adversarial Networks</strong>	
"P{QUMM#.}2"	Basic	SnykAdjacent::ML	What are GANs revolutionary for?	These models are game-changers in image generation, creating everything from art to realistic photos.	
nRxOn[90Zc	Basic	SnykAdjacent::ML	In ML: what does VAE stand for?	<strong>Variational Autoencoder</strong>	
u5ZYs:lA~j	Basic	SnykAdjacent::ML	in ML: what are VAEs good for?	"VAEs are great for tasks that involve compressing and generating 
high-quality images, offering applications in style transfer and more."	
A$sGj(Ru3G	Basic	SnykAdjacent::ML	in ML: what are&nbsp;<strong>Transformer Models good for?</strong>	"Known for their prowess in text, transformer models like GPT are 
revolutionizing text generation, translation, and automated writing"	
"k#g)vF.e|0"	Basic	SnykAdjacent::ML	In ML: what does RBM stand for?	<strong>Restricted Boltzmann Machine</strong>	
JNM^$):{~$	Basic	SnykAdjacent::ML	In ML: what are RBMs good for?	RBMs excel in understanding complex data patterns, aiding in tasks like feature learning and topic modeling.	
HNZ/21$q-j	Basic	SnykAdjacent::ML	In ML: how do generative language models learn?	Generative <strong><u>language </u></strong>models learn about patterns in language through training data	
i_r2mCk.ZC	Basic	SnykAdjacent::ML	in ML: given some text, what do generative language models predict?	What comes next	
L$~[/L8sQj	Basic	SnykAdjacent::ML	in ML: what two techniques did&nbsp;𝗧𝗿𝗮𝗻𝘀𝗳𝗼𝗿𝗺𝗲𝗿𝘀 move away from?	"moving away from traditional Deep Learning methodologies that were quite
 limiting such as Recurrent Neural Network (RNNs) and Convolutional 
Neural Network (CNNs) in NLP"	
k4*YRrelR2	Basic	SnykAdjacent::ML	In ML: what does&nbsp;RNN stand for?	Recurrent Neural Network	
vh,8}BR%:!	Basic	SnykAdjacent::ML	In ML: what does CNN stand for?	Convolutional Neural Network	
q;^up`06a(	Basic	SnykAdjacent::ML	In ML: What is a transformer self-attention mechanism?	Transformers use self-attention to efficiently process different parts of input data	
Jz<!CN;{Z	Basic	SnykAdjacent::ML	In ML: How do Transformers enable more efficient training than traditional RNNs?	𝗜𝗺𝗽𝗿𝗼𝘃𝗲𝗱 𝗣𝗮𝗿𝗮𝗹𝗹𝗲𝗹𝗶𝘇𝗮𝘁𝗶𝗼𝗻	
